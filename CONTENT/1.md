1. AI engineering is different from classical AI
2. Engineering layer on top of existing llms
3. LLMS
4. When LLMS were trained, no were expecte them to be great at (trainers did not intent to impart them), people belive it can only produce text    
  a. Writing code  
  b. translating   
  c. classifying a piece of text as p,n,n     
  d. creating poems    
  e. solving maths     
  f. creating images

5. These were domain specific task, 4-5 years ago you have to build models from scratch to do them
6. Earlier      
    a. Gather data    
    b. Do data engineering       
    c. train the model     
    d. analyse it    
    e. deploy it    
    f. Write an Engineering layer on top of it      

 7. Same model for    
   a. Create a chat bot   
   b. Create a maths tutor
   c. automate a workflow

8. The only complex propblem left was to add the engineering layer on top of it
  a. Provide the Right input   
  b. Right context      
  c. At the right time
9. Tradeoffs at every step
10. Not training the model right away, yes we will be doing some fine tuning.
11. We can productionize even without finetuning   
    a.Optimizing the prompts   
    b.Add different tools
    c.Add MCP servers
    d.Add a layer of RAG
    e.Do some EVAL

12. 3 Billion Param Model you can run on your CPU
13. 8 BIllion cant
# Tokenization  
15. 1 Token is not a word
16. A token can be a SubWord
17. A token can be a multi word
18. A token can be a single char
19. Tokens are present in a dictionary called Vocabulary
20. This is frozen
21. Token have a tokenId, this is the kv pair of the dictionary
22. tokens converted into tokenId
23. Vector/Embedding
24. Every tokenId converted to vectors
25. these vectors are also pre learned
26. Contractive learning
27. The vector will have fixed dimensions
28. 
