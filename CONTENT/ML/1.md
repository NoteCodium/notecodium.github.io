1. AI engineering is different from classical AI
2. Engineering layer on top of existing llms
3. LLMS
4. When LLMS were trained, no were expecte them to be great at (trainers did not intent to impart them), people belive it can only produce text    
  a. Writing code  
  b. translating   
  c. classifying a piece of text as p,n,n     
  d. creating poems    
  e. solving maths     
  f. creating images

5. These were domain specific task, 4-5 years ago you have to build models from scratch to do them
6. Earlier      
    a. Gather data    
    b. Do data engineering       
    c. train the model     
    d. analyse it    
    e. deploy it    
    f. Write an Engineering layer on top of it      

 7. Same model for    
   a. Create a chat bot   
   b. Create a maths tutor
   c. automate a workflow

8. The only complex propblem left was to add the engineering layer on top of it
  a. Provide the Right input   
  b. Right context      
  c. At the right time
9. Tradeoffs at every step
10. Not training the model right away, yes we will be doing some fine tuning.
11. We can productionize even without finetuning   
    a.Optimizing the prompts   
    b.Add different tools
    c.Add MCP servers
    d.Add a layer of RAG
    e.Do some EVAL

12. 3 Billion Param Model you can run on your CPU
13. 8 BIllion cant
# Tokenization  
15. 1 Token is not a word
16. A token can be a SubWord
17. A token can be a multi word
18. A token can be a single char
19. Tokens are present in a dictionary called Vocabulary
20. This is frozen
21. Token have a tokenId, this is the kv pair of the dictionary
22. tokens converted into tokenId
23. Vector/Embedding
24. Every tokenId converted to vectors
25. these vectors are also pre learned
26. Contractive learning
27. The vector will have fixed dimensions
28. Token embeddings are addded with positional embeddings
29. positional embeddings are prelearned vectors
30. Relavance of a word is impacted by the position within a sentence
31. Same for each language?
32. The result is input Embedding
33. Input to transfomer clock?/GPT (ML starts from here)
34. TikToken is a Byte level (1char) tokenizer used for OpenAI models open source, BPE Byte pair encoding


```py
import tiktoken

text= "i like to play football"
enc=tiktoken.encoding_for_model("gpt-4o")
tokens=enc.encode(text)

print("Tokens:", [enc.decode(t) for t in tokens])
print("Token IDs:", tokens)
```

35. The later tokens will also pick the space at the beginning
36. this algo is deterministic and not intelligent
37. Counterterrorizm ka izm will be brokern as separate token
38. Useful prefixes and suffixes
39. But sometime it does not if its frequency is very high

```py
import tiktoken
enc=tiktoken.encoding_for_model("gpt-4o")
print("Total vocab size", enc.n_vocab)
#200019 (2 lakh)
print("Mergeable tokens", len(enc._mergeable_ranks))
#doubt 199998
print("Special tokens", len(enc._special_tokens))
#beginning of sequence, End of seqence 2

```



